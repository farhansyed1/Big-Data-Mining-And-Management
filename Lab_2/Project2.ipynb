{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O92e4AODp3T0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O92e4AODp3T0",
        "outputId": "fbba1a4f-9da3-4070-f1f0-d64669997e08"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4acefbab",
      "metadata": {},
      "source": [
        "## Preprocessing\n",
        "Here, we preprocess raw ID-paired edges into the PyG dataset format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99303505",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464d98f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464d98f5",
        "outputId": "16041171-bf21-40db-ff95-a922eafe66d5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "\n",
        "class CustomGraphDataset(InMemoryDataset):\n",
        "    def __init__(self, root, filename, transform=None, pre_transform=None):\n",
        "        self.filename = filename\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "        # Allowlist PyG classes\n",
        "        from torch_geometric.data.data import DataEdgeAttr\n",
        "        torch.serialization.add_safe_globals([DataEdgeAttr])\n",
        "\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only= False)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [self.filename]  # Dynamically return the provided filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # Generate a unique processed filename based on the input file\n",
        "        return [f\"{self.filename.split('.')[0]}.pt\"]\n",
        "\n",
        "    def download(self):\n",
        "        # Add download logic here if needed\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        # Read edges from the specified file\n",
        "        edges = []\n",
        "        with open(self.raw_paths[0], 'r') as f:\n",
        "            for line in f:\n",
        "                src, tgt = line.strip().split()\n",
        "                edges.append([int(src), int(tgt)])\n",
        "\n",
        "        # Create edge_index tensor\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        # Calculate Number of nodes using edge_index\n",
        "        node_set = set()\n",
        "        for edge in edges:\n",
        "            node_set.add(edge[0])\n",
        "            node_set.add(edge[1])\n",
        "        num_nodes = len(node_set)\n",
        "        # Create Data object\n",
        "        data = Data(edge_index=edge_index, num_nodes=num_nodes)\n",
        "        data.x = torch.arange(num_nodes, dtype=torch.long)\n",
        "        # Apply optional pre-processing\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data)\n",
        "\n",
        "        # Save processed data\n",
        "        torch.save(self.collate([data]), self.processed_paths[0])\n",
        "\n",
        "# Usage Example\n",
        "dataset = CustomGraphDataset(\n",
        "    root='',\n",
        "    filename='raw_edges.txt'  # Specify which file to load\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a807ef",
      "metadata": {},
      "source": [
        "Data overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b73f5c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b73f5c8",
        "outputId": "3bfea133-be9d-4768-caab-0e8e7a6d59c1"
      },
      "outputs": [],
      "source": [
        "def print_dataset_info(dataset, dataset_name=\"Dataset\"):\n",
        "    \"\"\"Prints basic information about a PyG dataset.\"\"\"\n",
        "    data = dataset[0]  # Get the graph object\n",
        "\n",
        "    print(f\"\\n=== {dataset_name} Information ===\")\n",
        "    print(f\"Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"Number of edges: {data.edge_index.size(1)}\")\n",
        "    print(f\"Contains node features: {'x' in data}\")\n",
        "    print(f\"Contains edge features: {'edge_attr' in data}\")\n",
        "    print(f\"Contains graph labels: {'y' in data}\")\n",
        "print_dataset_info(dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a5a34c",
      "metadata": {},
      "source": [
        "## Split dataset\n",
        "we are splitting the dataset into three distinct subsets: the training graph, validation graph, and testing graph. The purpose of this split is to ensure that our model can learn effectively, validate its performance during training, and evaluate its generalization capabilities on unseen data.\n",
        "- The testing graph has the largest number of edges due to the masking process applied to the original dataset.\n",
        "- By carefully selecting edges for each subset, we create a testing environment while still providing sufficient data for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f38c6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31f38c6e",
        "outputId": "04ffdbd5-5d05-4cc3-8b3b-5f8a4ba5c6bb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "edge_transform = RandomLinkSplit(num_val=0.2, num_test=0.2,\n",
        "                                is_undirected=True, add_negative_train_samples=False)\n",
        "train_data, val_data, test_data = edge_transform(dataset.data)\n",
        "print(train_data)\n",
        "print(val_data)\n",
        "print(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1c1c05",
      "metadata": {},
      "source": [
        "## GraphSAGE\n",
        "Below is the implementation for GraphSAGE, please fill in the TODO blanks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "97cc1cc1",
      "metadata": {
        "id": "97cc1cc1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from torch.nn import Embedding\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, embedding_dim, hidden_dim, out_dim, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.embedding = # TODO\n",
        "        \n",
        "        # Create layer sequence\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        in_dim = embedding_dim\n",
        "        for _ in range(num_layers-1):\n",
        "            self.convs.append(SAGEConv(in_dim, hidden_dim))\n",
        "            in_dim = hidden_dim\n",
        "        self.convs.append(SAGEConv(in_dim, out_dim))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.embedding(x)\n",
        "        for conv in self.convs:\n",
        "            # TODO\n",
        "        return x\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.lin = # TODO\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src = z[edge_index[0]]\n",
        "        dst = z[edge_index[1]]\n",
        "        return self.lin(torch.cat([src, dst], dim=1)).squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064bd15c",
      "metadata": {},
      "source": [
        "## Configure device for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f08dec5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f08dec5b",
        "outputId": "d29ef282-dd32-4f0d-de28-4cca22fd06ba"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cuda\n",
        "# device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')# apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d50d4d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50d4d85",
        "outputId": "be5a4772-3e2d-4c77-82b6-bc3886e0ff15"
      },
      "outputs": [],
      "source": [
        "def train(model_graphsage, predictor, optimizer):\n",
        "    model_graphsage.train()\n",
        "    predictor.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass to get node embeddings\n",
        "    z = model_graphsage(train_data.x.to(device), train_data.edge_index.to(device))\n",
        "\n",
        "    # Positive edges\n",
        "    pos_edge_index = train_data.edge_label_index.to(device)\n",
        "    # Negative sampling\n",
        "    neg_edge_index = negative_sampling(\n",
        "        edge_index=train_data.edge_index.to(device),\n",
        "        num_nodes=train_data.num_nodes,\n",
        "        num_neg_samples=pos_edge_index.size(1),\n",
        "    ).to(device)\n",
        "\n",
        "    # Combine positive and negative edges\n",
        "    edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "    labels = torch.cat([\n",
        "        torch.ones(pos_edge_index.size(1)),\n",
        "        torch.zeros(neg_edge_index.size(1))\n",
        "    ], dim=0).to(device)\n",
        "\n",
        "    # Prediction scores\n",
        "    scores = predictor(z, edge_index)\n",
        "\n",
        "    # Loss and backwarde\n",
        "    loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model_graphsage, predictor, data):\n",
        "    model_graphsage.eval()\n",
        "    predictor.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model_graphsage(data.x.to(device), data.edge_index.to(device))\n",
        "        scores = predictor(z, data.edge_label_index.to(device))\n",
        "        pred = scores.sigmoid()\n",
        "        loss = F.binary_cross_entropy_with_logits(scores, data.edge_label.to(device))\n",
        "        auc = roc_auc_score(data.edge_label.cpu().numpy(), pred.cpu().numpy())\n",
        "\n",
        "        # Calculate additional metrics\n",
        "        threshold = 0.5\n",
        "        predicted_labels = (pred >= threshold).int()\n",
        "        precision = precision_score(data.edge_label.cpu().numpy(), predicted_labels.cpu().numpy())\n",
        "        recall = recall_score(data.edge_label.cpu().numpy(), predicted_labels.cpu().numpy())\n",
        "        f1 = f1_score(data.edge_label.cpu().numpy(), predicted_labels.cpu().numpy())\n",
        "\n",
        "        return loss.item(), auc, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864a1a91",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "embedding_dims = # TODO\n",
        "num_layers_list = # TODO\n",
        "lr_list = # TODO\n",
        "# Move data to device\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "graphsage_auc_scores = {}\n",
        "verbose = False\n",
        "for embedding_dim in embedding_dims:\n",
        "    for num_layers in num_layers_list:\n",
        "        for lr in lr_list:\n",
        "            # Initialize model with current parameters\n",
        "            model = GraphSAGE(\n",
        "                num_nodes=train_data.num_nodes,\n",
        "                embedding_dim=embedding_dim,\n",
        "                hidden_dim=256,  # Fixed hidden dimension\n",
        "                out_dim=256,\n",
        "                num_layers=num_layers  # Modified to accept layer count\n",
        "            ).to(device)\n",
        "\n",
        "            predictor = LinkPredictor(in_dim=256).to(device)\n",
        "            optimizer = torch.optim.Adam(\n",
        "                list(model.parameters()) + list(predictor.parameters()),\n",
        "                lr=lr\n",
        "            )\n",
        "            # Training loop\n",
        "            for epoch in tqdm(range(1, 20)):\n",
        "                loss = train(model, predictor, optimizer)\n",
        "                val_loss, val_auc, val_precision, val_recall, val_f1 = test(model, predictor, val_data)\n",
        "                test_loss, test_auc, test_precision, test_recall, test_f1 = test(model, predictor, test_data)\n",
        "                if verbose:\n",
        "                    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "                    print(f'Validation - Loss: {val_loss:.4f}, AUC: {val_auc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n",
        "                    print(f'Test - Loss: {test_loss:.4f}, AUC: {test_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "                    print('-' * 80)  # Separator line for better readability\n",
        "                \n",
        "            _, test_auc, _, _, test_f1 = test(model, predictor, test_data)\n",
        "            graphsage_auc_scores[(embedding_dim, num_layers, lr)] = test_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a7c4861",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot for GraphSAGE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fixed_lr = 0.01  # Choose a fixed learning rate for the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Extract scores for chosen learning rate\n",
        "a = np.array([[graphsage_auc_scores[(ed, nl, fixed_lr)] \n",
        "                for ed in embedding_dims] \n",
        "                for nl in num_layers_list])\n",
        "\n",
        "# Create heatmap\n",
        "heatmap = plt.imshow(a, cmap=\"viridis\", interpolation=\"nearest\", vmin=0.5, vmax=1.0)\n",
        "plt.colorbar(heatmap, label=\"AUC Score\")\n",
        "\n",
        "# Axis labels and ticks\n",
        "plt.xticks(ticks=range(len(embedding_dims)), \n",
        "           labels=[str(d) for d in embedding_dims])\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "\n",
        "plt.yticks(ticks=range(len(num_layers_list)), \n",
        "           labels=[str(n) for n in num_layers_list])\n",
        "plt.ylabel(\"Number of Layers\")\n",
        "\n",
        "plt.title(f\"Link Prediction Performance (LR={fixed_lr})\")\n",
        "\n",
        "# Add text annotations for the AUC scores\n",
        "for i in range(len(num_layers_list)):\n",
        "    for j in range(len(embedding_dims)):\n",
        "        plt.text(j, i, f\"{a[i, j]:.2f}\", ha='center', va='center', color='white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"graphsage_auc_scores_lr_{fixed_lr}.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "58c054b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58c054b7",
        "outputId": "56bab200-6425-4bcf-8aa7-4bc9c439e708"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import LGConv\n",
        "\n",
        "class LightGCN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, embedding_dim, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.embedding = # TODO\n",
        "        self.convs = torch.nn.ModuleList([LGConv() for _ in range(num_layers)])\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.embedding(x)\n",
        "        out = x / (self.num_layers + 1)  # Initial contribution\n",
        "\n",
        "        for conv in self.convs:\n",
        "            # TODO\n",
        "\n",
        "        return out\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.lin = # TODO\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src = z[edge_index[0]]\n",
        "        dst = z[edge_index[1]]\n",
        "        return self.lin(torch.cat([src, dst], dim=1)).squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b160b4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b160b4f",
        "outputId": "504fa054-9213-4c2c-e4c1-67fda1d2c990"
      },
      "outputs": [],
      "source": [
        "# Move data to device\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2cde6c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "embedding_dims = # TODO\n",
        "num_layers_list = # TODO\n",
        "lr_list = # TODO\n",
        "# Move data to device\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "lightgcn_auc_scores = {}\n",
        "verbose = False\n",
        "for embedding_dim in embedding_dims:\n",
        "    for num_layers in num_layers_list:\n",
        "        for lr in lr_list:\n",
        "            # Initialize model with current parameters\n",
        "            model = LightGCN(\n",
        "                num_nodes=train_data.num_nodes,\n",
        "                embedding_dim=embedding_dim,\n",
        "                num_layers=num_layers  # Modified to accept layer count\n",
        "            ).to(device)\n",
        "\n",
        "            predictor = LinkPredictor(in_dim=embedding_dim).to(device)\n",
        "            optimizer = torch.optim.Adam(\n",
        "                list(model.parameters()) + list(predictor.parameters()),\n",
        "                lr=lr\n",
        "            )\n",
        "            # Training loop\n",
        "            for epoch in tqdm(range(1, 20)):\n",
        "                loss = train(model, predictor, optimizer)\n",
        "                val_loss, val_auc, val_precision, val_recall, val_f1 = test(model, predictor, val_data)\n",
        "                test_loss, test_auc, test_precision, test_recall, test_f1 = test(model, predictor, test_data)\n",
        "                if verbose:\n",
        "                    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "                    print(f'Validation - Loss: {val_loss:.4f}, AUC: {val_auc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n",
        "                    print(f'Test - Loss: {test_loss:.4f}, AUC: {test_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "                    print('-' * 80)  # Separator line for better readability\n",
        "                \n",
        "            _, test_auc, _, _, test_f1 = test(model, predictor, test_data)\n",
        "            lightgcn_auc_scores[(embedding_dim, num_layers, lr)] = test_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20ee8449",
      "metadata": {},
      "source": [
        "## Plot for LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OCr-ATy8rubg",
      "metadata": {
        "id": "OCr-ATy8rubg"
      },
      "outputs": [],
      "source": [
        "# Plot for LightGCN\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fixed_lr = 0.1  # Choose a fixed learning rate for the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Extract scores for chosen learning rate\n",
        "a = np.array([[lightgcn_auc_scores[(ed, nl, fixed_lr)] \n",
        "                for ed in embedding_dims] \n",
        "                for nl in num_layers_list])\n",
        "\n",
        "# Create heatmap\n",
        "heatmap = plt.imshow(a, cmap=\"viridis\", interpolation=\"nearest\", vmin=0.5, vmax=1.0)\n",
        "plt.colorbar(heatmap, label=\"auc Score\")\n",
        "\n",
        "# Axis labels and ticks\n",
        "plt.xticks(ticks=range(len(embedding_dims)), \n",
        "           labels=[str(d) for d in embedding_dims])\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "\n",
        "plt.yticks(ticks=range(len(num_layers_list)), \n",
        "           labels=[str(n) for n in num_layers_list])\n",
        "plt.ylabel(\"Number of Layers\")\n",
        "\n",
        "plt.title(f\"Link Prediction Performance (LR={fixed_lr})\")\n",
        "\n",
        "# Add text annotations for the AUC scores\n",
        "for i in range(len(num_layers_list)):\n",
        "    for j in range(len(embedding_dims)):\n",
        "        plt.text(j, i, f\"{a[i, j]:.2f}\", ha='center', va='center', color='white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"lightgcn_auc_scores_lr_{fixed_lr}.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8811ab0a",
      "metadata": {},
      "source": [
        "## Export Model Weights For Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef70c11a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Put your best model configs here\n",
        "model = GraphSAGE(\n",
        "                num_nodes=train_data.num_nodes,\n",
        "                embedding_dim= ,# TODO\n",
        "                hidden_dim=256,  # Fixed hidden dimension\n",
        "                out_dim=256,\n",
        "                num_layers=  # TODO\n",
        "            ).to(device)\n",
        "\n",
        "predictor = LinkPredictor(in_dim=256).to(device)\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model.parameters()) + list(predictor.parameters()),\n",
        "    lr= # TODO\n",
        ")\n",
        "# Training loop\n",
        "for epoch in tqdm(range(1, 20)):\n",
        "    loss = train(model, predictor, optimizer)\n",
        "    val_loss, val_auc, val_precision, val_recall, val_f1 = test(model, predictor, val_data)\n",
        "    test_loss, test_auc, test_precision, test_recall, test_f1 = test(model, predictor, test_data)\n",
        "    if verbose:\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Validation - Loss: {val_loss:.4f}, AUC: {val_auc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n",
        "        print(f'Test - Loss: {test_loss:.4f}, AUC: {test_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "        print('-' * 80)  # Separator line for better readability\n",
        "    \n",
        "_, test_auc, _, _, _ = test(model, predictor, test_data)\n",
        "print(f\"GraphSAGE Test AUC: {test_auc:.4f}\")\n",
        "torch.save(model.state_dict(), \"best_graphsage_model.pth\")\n",
        "\n",
        "\n",
        "model = LightGCN(\n",
        "                num_nodes=train_data.num_nodes,\n",
        "                embedding_dim=, # TODO\n",
        "                num_layers=  # TODO\n",
        "            ).to(device)\n",
        "\n",
        "predictor = LinkPredictor(in_dim=embedding_dim).to(device)\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(model.parameters()) + list(predictor.parameters()),\n",
        "    lr= # TODO\n",
        ")\n",
        "# Training loop\n",
        "for epoch in tqdm(range(1, 20)):\n",
        "    loss = train(model, predictor, optimizer)\n",
        "    val_loss, val_auc, val_precision, val_recall, val_f1 = test(model, predictor, val_data)\n",
        "    test_loss, test_auc, test_precision, test_recall, test_f1 = test(model, predictor, test_data)\n",
        "    if verbose:\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "        print(f'Validation - Loss: {val_loss:.4f}, AUC: {val_auc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}')\n",
        "        print(f'Test - Loss: {test_loss:.4f}, AUC: {test_auc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}')\n",
        "        print('-' * 80)  # Separator line for better readability\n",
        "    \n",
        "_, test_auc, _, _, test_f1 = test(model, predictor, test_data)\n",
        "print(f\"LightGCN Test AUC: {test_auc:.4f}\")\n",
        "torch.save(model.state_dict(), \"best_lightgcn_model.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
